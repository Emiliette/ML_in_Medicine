\documentclass[11pt,twocolumn]{article}
\usepackage{amsmath,amssymb}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{hyperref}
\usepackage{geometry}
\geometry{margin=0.75in}

\title{\textbf{ECG Heartbeat Classification Using Random Forest}}
\author{22BA13158 -- Hoang Kim Huong}
\date{}

\begin{document}
\maketitle

\section{Introduction}
Electrocardiogram (ECG) signals are widely used for monitoring cardiac activity and diagnosing heart-related diseases. Manual analysis of long-term ECG recordings is time-consuming and requires expert knowledge. Therefore, automatic heartbeat classification has become an important research topic in biomedical signal processing and machine learning.
\vspace{0.15cm}
\\
\noindent In this report, I address the problem of ECG heartbeat classification using a classical machine learning approach, a Random Forest classifier, which is implemented to classify individual heartbeats from the MIT-BIH Arrhythmia dataset. The effectiveness of ensemble-based machine learning methods is evaluated, and their characteristics are compared with the deep learning approaches reported in the original paper \cite{OP}.

\section{Problem Statement}
Classify individual ECG heartbeats into one of five predefined categories according to the AAMI standard. Given a segmented heartbeat represented as a fixed-length numerical vector, the model will predict the correct heartbeat class. This is formulated as a multi-class classification problem.

\section{Data Description}
The dataset is derived from the MIT-BIH Arrhythmia Dataset and downloaded from Kaggle. After extracting the dataset archive, two CSV files are obtained: mitbih\_train.csv and mitbih\_test.csv.
\vspace{0.15cm}
\\
\noindent Each row corresponds to a single ECG heartbeat that has been segmented from a continuous ECG recording. Every heartbeat is represented by 187 numerical features, which correspond to normalized amplitude samples of the ECG waveform. This fixed-length representation enables the direct application of traditional machine learning algorithms without additional signal processing steps.
\par\vspace{0.15cm}
\noindent The last column is the class label. There are five heartbeat classes encoded as integers from 0 to 4, following the AAMI standard:
\begin{itemize}
\item Class 0: Normal beats (N)
\item Class 1: Supraventricular ectopic beats (S)
\item Class 2: Ventricular ectopic beats (V)
\item Class 3: Fusion beats (F)
\item Class 4: Unknown or paced beats (Q)
\end{itemize}

\noindent The training set contains 87,554 samples, while the test set contains about 21,892 samples. A notable characteristic is its strong class imbalance, with normal beats dominating the data distribution. This imbalance must be considered during model training and evaluation.

\section{Methodology}
\subsection{Model Description}
A Random Forest classifier is implemented using the \texttt{scikit-learn} library. Random Forest is an ensemble learning method that constructs multiple decision trees using bootstrap sampling and random feature selection. The final prediction is obtained by majority voting across all trees.
\vspace{0.15cm}
\\
\noindent Each ECG heartbeat is treated as a 187-dimensional feature vector and directly fed into the Random Forest model. No explicit feature extraction or dimensionality reduction is applied. Non-linear decision boundaries are learned through recursive feature splitting within individual trees, allowing the model to capture complex relationships in the ECG data.

\subsection{Training Procedure}
The model is trained on the provided training set, while performance is evaluated on the independent test set. To mitigate the impact of class imbalance, the class\_weight option is explored in the Random Forest classifier. Model performance is assessed using accuracy and macro-averaged F1-score.

\subsection{Hyperparameter Experiments}
To analyze the impact of hyperparameters on classification performance, several Random Forest parameters are experimentally varied. The main hyperparameters investigated include the number of trees (n\_estimators), maximum tree depth (max\_depth), and the use of class weighting.

\begin{table}[h]
\centering
\caption{Hyperparameter Experiments with Random Forest}
\resizebox{\columnwidth}{!}{%
\begin{tabular}{cccc}
\toprule
\texttt{n\_estimators} & \texttt{max\_depth} & \texttt{class\_weight} & Macro F1 \\
\midrule
400 & None & Balanced\_subsample & 0.86 \\
100 & None & No & 0.87 \\
200 & None & No & 0.88 \\
200 & 20 & No & 0.85 \\
200 & 20 & Balanced & 0.85 \\
\bottomrule
\end{tabular}
}
\end{table}

\noindent The experimental results show that increasing the number of trees from 100 to 200 leads to a slight improvement in macro F1-score, indicating improved ensemble stability. However, further increasing the number of estimators to 400 does not provide additional benefits, suggesting performance saturation. Limiting the tree depth to 20 slightly degrades performance, which implies that deeper trees are better suited to capture the complex morphological patterns of ECG heartbeats. Moreover, applying class weighting does not consistently improve macro F1-score, indicating that the Random Forest model is already capable of handling class imbalance effectively when trained with a sufficient number of trees.

\section{Comparison with the Original Paper}
The original paper by Hannun et al. (2019) proposed a deep neural network for arrhythmia detection and achieved cardiologist-level performance using a very large-scale ECG dataset \cite{OP}. Their approach relies on end-to-end deep learning, where hierarchical features are automatically learned from raw ECG signals through multiple convolutional layers.
\vspace{0.15cm}
\\
\noindent In contrast, this report adopts a classical machine learning approach using a Random Forest classifier trained on pre-segmented and preprocessed heartbeats from the MIT-BIH dataset. The main differences between the two approaches are that the model complexity is significantly lower in this work, resulting in reduced computational cost and faster training time, and the dataset used in this study is much smaller than the dataset employed in the original paper, which limits the achievable performance.
\vspace{0.15cm}
\\
\noindent Despite these differences, both approaches demonstrate the importance of learning discriminative patterns from ECG signals for accurate heartbeat classification. While the deep learning model in the original paper outperforms classical methods in terms of accuracy and robustness, the Random Forest model remains competitive for smaller datasets and offers better interpretability. This comparison highlights the trade-off between model complexity and practicality in real-world clinical applications.
\vspace{-0.1cm}
\section{Conclusion}
This report presents a machine learning approach for ECG heartbeat classification using a Random Forest classifier. Despite its simplicity compared to deep learning models, the Random Forest achieves reasonable performance on the MIT-BIH dataset and demonstrates robustness to noisy input features.
\vspace{0.15cm}
\noindent Experimental results indicate that proper hyperparameter tuning and class imbalance handling are crucial for achieving good performance. Compared to deep neural networks reported, the proposed approach is computationally efficient and easier to interpret, making it suitable for resource-constrained or explainability-focused applications. Future work may explore feature engineering or hybrid approaches combining machine learning and deep learning techniques.

\renewcommand{\bibname}{References} 

\bibliographystyle{ieeetr}
\bibliography{references}

\end{document}
